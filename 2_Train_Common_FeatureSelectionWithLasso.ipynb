{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This notebook takes output from ProcessingTrain_Test_Data\n",
    "# Purpose: Use Lasso Regression as a feature selection tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in train data set and target variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load train data\n",
    "Training = pd.read_csv('TrainingDataSet_common_features.csv')\n",
    "\n",
    "# Load test data\n",
    "Target = pd.read_csv('Target_Variable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X189</th>\n",
       "      <th>X185</th>\n",
       "      <th>X184</th>\n",
       "      <th>X187</th>\n",
       "      <th>X186</th>\n",
       "      <th>X181</th>\n",
       "      <th>X180</th>\n",
       "      <th>X183</th>\n",
       "      <th>X182</th>\n",
       "      <th>X291</th>\n",
       "      <th>...</th>\n",
       "      <th>X2_e</th>\n",
       "      <th>X2_d</th>\n",
       "      <th>X2_b</th>\n",
       "      <th>X2_a</th>\n",
       "      <th>X2_n</th>\n",
       "      <th>X2_m</th>\n",
       "      <th>X2_k</th>\n",
       "      <th>X2_j</th>\n",
       "      <th>X2_i</th>\n",
       "      <th>X2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 553 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X189  X185  X184  X187  X186  X181  X180  X183  X182  X291  ...   X2_e  \\\n",
       "0     1     0     1     1     0     0     0     0     0     0  ...      0   \n",
       "1     1     0     0     1     0     0     0     0     0     0  ...      0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "3     0     0     0     0     0     0     0     0     0     1  ...      0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   X2_d  X2_b  X2_a  X2_n  X2_m  X2_k  X2_j  X2_i  X2_h  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     1     0     0     0     0     0  \n",
       "3     0     0     0     1     0     0     0     0     0  \n",
       "4     0     0     0     1     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 553 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y\n",
       "0  130.81\n",
       "1   88.53\n",
       "2   76.26\n",
       "3   80.62\n",
       "4   78.02"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets save the feature names in a variable \n",
    "FeatureName = Training.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the Lasso library required \n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function came from https://chrisalbon.com/machine-learning/lasso_regression_in_scikit.html\n",
    "# It takes in a list of alphas and returns all the coefficients of the features for each alpha level\n",
    "\n",
    "def lasso(alphas):\n",
    "    '''\n",
    "    Takes in a list of alphas. Outputs a dataframe containing the coefficients of lasso regressions from each alpha.\n",
    "    '''\n",
    "    # Create an empty data frame\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Create a column of feature names\n",
    "    df['Feature Name'] = FeatureName\n",
    "\n",
    "    # For each alpha value in the list of alpha values,\n",
    "    for alpha in alphas:\n",
    "        # Create a lasso regression with that alpha value,\n",
    "        lasso = Lasso(alpha=alpha)\n",
    "\n",
    "        # Fit the lasso regression\n",
    "        lasso.fit(Predictors, Targets)\n",
    "\n",
    "        # Create a column name for that alpha value\n",
    "        column_name = 'Alpha = %f' % alpha\n",
    "\n",
    "        # Create a column of coefficient values\n",
    "        df[column_name] = lasso.coef_\n",
    "\n",
    "    # Return the datafram    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets use this function to find the coefficients for alpha values of .1, 1 and 10\n",
    "\n",
    "# Lets create the X and y array\n",
    "# First get the values from the panda data frame\n",
    "Training_array = Training.values\n",
    "# Now get the features\n",
    "Predictors = Training_array[:]\n",
    "# Now get the target\n",
    "Target_array = Target.values\n",
    "Targets = Target_array[:,0]\n",
    "\n",
    "# Now lets create the list of alphas\n",
    "Alpha = [.1,1,10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Alpha = 0.100000</th>\n",
       "      <th>Alpha = 1.000000</th>\n",
       "      <th>Alpha = 10.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X185</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X187</td>\n",
       "      <td>0.277482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X186</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X291</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X119</td>\n",
       "      <td>4.066625</td>\n",
       "      <td>2.619817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X295</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X294</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X296</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>X112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>X110</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>X111</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>X116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>X117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>X114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>X115</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>X376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>X377</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>X374</td>\n",
       "      <td>0.076519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>X375</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>X372</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>X0_s</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>X0_r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>X0_u</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>X0_t</td>\n",
       "      <td>-0.020137</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>X0_w</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>X0_v</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>X0_y</td>\n",
       "      <td>0.880640</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>X0_x</td>\n",
       "      <td>0.668643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>X0_z</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>X4_d</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>X2_t</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>X4_a</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>X2_r</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>X4_c</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>X8_x</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>X2_z</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>X2_y</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>X2_x</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>X2_g</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>X2_f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>X2_e</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>X2_d</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>X2_b</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>X2_a</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>X2_n</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>X2_m</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>X2_k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>X2_j</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>X2_i</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>X2_h</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Name  Alpha = 0.100000  Alpha = 1.000000  Alpha = 10.000000\n",
       "0           X189          0.000000          0.000000                  0\n",
       "1           X185         -0.000000         -0.000000                 -0\n",
       "2           X184          0.000000          0.000000                  0\n",
       "3           X187          0.277482          0.000000                  0\n",
       "4           X186         -0.000000          0.000000                 -0\n",
       "5           X181          0.000000          0.000000                 -0\n",
       "6           X180          0.000000          0.000000                  0\n",
       "7           X183          0.000000          0.000000                  0\n",
       "8           X182          0.000000          0.000000                 -0\n",
       "9           X291         -0.000000         -0.000000                 -0\n",
       "10          X290          0.000000          0.000000                  0\n",
       "11          X293          0.000000          0.000000                  0\n",
       "12          X119          4.066625          2.619817                  0\n",
       "13          X295         -0.000000         -0.000000                 -0\n",
       "14          X294         -0.000000          0.000000                  0\n",
       "15          X297          0.000000          0.000000                  0\n",
       "16          X296         -0.000000         -0.000000                 -0\n",
       "17          X112          0.000000          0.000000                  0\n",
       "18          X113          0.000000          0.000000                  0\n",
       "19          X110         -0.000000         -0.000000                 -0\n",
       "20          X111         -0.000000         -0.000000                 -0\n",
       "21          X116          0.000000          0.000000                  0\n",
       "22          X117          0.000000          0.000000                 -0\n",
       "23          X114          0.000000         -0.000000                 -0\n",
       "24          X115         -0.000000         -0.000000                 -0\n",
       "25          X376          0.000000          0.000000                  0\n",
       "26          X377         -0.000000          0.000000                  0\n",
       "27          X374          0.076519          0.000000                  0\n",
       "28          X375         -0.000000          0.000000                  0\n",
       "29          X372         -0.000000         -0.000000                 -0\n",
       "..           ...               ...               ...                ...\n",
       "523         X0_s          0.000000         -0.000000                 -0\n",
       "524         X0_r          0.000000          0.000000                  0\n",
       "525         X0_u         -0.000000         -0.000000                 -0\n",
       "526         X0_t         -0.020137         -0.000000                 -0\n",
       "527         X0_w          0.000000          0.000000                  0\n",
       "528         X0_v         -0.000000         -0.000000                  0\n",
       "529         X0_y          0.880640         -0.000000                 -0\n",
       "530         X0_x          0.668643          0.000000                  0\n",
       "531         X0_z         -0.000000         -0.000000                 -0\n",
       "532         X4_d         -0.000000         -0.000000                 -0\n",
       "533         X2_t         -0.000000          0.000000                  0\n",
       "534         X4_a         -0.000000         -0.000000                  0\n",
       "535         X2_r          0.000000          0.000000                  0\n",
       "536         X4_c          0.000000          0.000000                  0\n",
       "537         X8_x         -0.000000          0.000000                 -0\n",
       "538         X2_z         -0.000000         -0.000000                 -0\n",
       "539         X2_y         -0.000000         -0.000000                  0\n",
       "540         X2_x          0.000000         -0.000000                  0\n",
       "541         X2_g          0.000000          0.000000                  0\n",
       "542         X2_f          0.000000         -0.000000                 -0\n",
       "543         X2_e         -0.000000         -0.000000                 -0\n",
       "544         X2_d         -0.000000         -0.000000                 -0\n",
       "545         X2_b         -0.000000         -0.000000                 -0\n",
       "546         X2_a         -0.000000         -0.000000                  0\n",
       "547         X2_n         -0.000000         -0.000000                 -0\n",
       "548         X2_m         -0.000000         -0.000000                 -0\n",
       "549         X2_k          0.000000          0.000000                  0\n",
       "550         X2_j         -0.000000         -0.000000                 -0\n",
       "551         X2_i          0.000000          0.000000                  0\n",
       "552         X2_h          0.000000         -0.000000                 -0\n",
       "\n",
       "[553 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now run this\n",
    "\n",
    "lasso(Alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So the idea of a lasso regression is to reduce the magnitude of the weights to avoid over fitting\n",
    "# The way it does this is by taking the L1 norm (Take the absolute values of the weights, then sum them) and \n",
    "# subtracting it from the current coefficient of a feature. This mode of regularisation results in some\n",
    "# of the weights of the features to become zero and thus drop out of the model\n",
    "# So this is my rationale for using this as a feature selection tool\n",
    "\n",
    "# From my analysis of 1, 0.1 and 10, I can see that at different alpha levels, I have different feature weights\n",
    "# set to 0. Question is which alpha level do I choose as the different alpha levels would have different\n",
    "# features selected. Hmmmm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets use cross validation technique to find a suitable alpha value\n",
    "\n",
    "# The idea is for each alpha value, do the following:\n",
    "# Divide the data set into a number of sets\n",
    "# Hide one set, use the other sets to train \n",
    "# The use the model to now make predictions on the hidden set\n",
    "# Report the quality of the predictions for the hidden set\n",
    "# Repeat this x amount of times and report x amount of metrics\n",
    "\n",
    "# There is a library that does this called cross_val_score\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function is from 'https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-\n",
    "# boosting-gbm-python/. They used the function to tune gradient boosting classification algorithm using the \n",
    "# cross validation method\n",
    "\n",
    "# I modified this algorithm and used it to tune the parameters for my lasso regression \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, target, predictors, performCV=True, cv_folds=5):\n",
    "    \n",
    "    #Fit the algorithm on the training data\n",
    "    alg.fit(predictors,target)\n",
    "        \n",
    "    #Use the model fitted to predict training set:\n",
    "    dtrain_predictions = alg.predict(predictors)\n",
    "    \n",
    "    # Evaluate the predictions made by this fit\n",
    "    # The quality control I chose for my fit include mean squared error and R_squared\n",
    "    MSE=metrics.mean_squared_error(target,dtrain_predictions)\n",
    "    R_squared = metrics.r2_score(target,dtrain_predictions)\n",
    "    \n",
    "    \n",
    "    # The above code is without any cross validation where all the data is used to train the model.\n",
    "    # Well we know that leaves us open to overfitting. So to mitigate that, lets do some cross validation\n",
    "    # Also we will use this CV to tune some of our parameters \n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_scoreMSE = cross_validation.cross_val_score(alg, predictors,target, cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "        cv_scoreR_squared = cross_validation.cross_val_score(alg, predictors,target, cv=cv_folds, scoring='r2')\n",
    "    \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"MSE : %.4g\" % MSE\n",
    "    print \"R_squared : %.6g\" % R_squared\n",
    "    \n",
    "    \n",
    "    if performCV:\n",
    "        print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_scoreMSE),np.std(cv_scoreMSE),np.min(cv_scoreMSE),np.max(cv_scoreMSE))\n",
    "        print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_scoreR_squared),np.std(cv_scoreR_squared),np.min(cv_scoreR_squared),np.max(cv_scoreR_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:1665: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "MSE : 61.12\n",
      "R_squared : 0.619701\n",
      "CV Score : Mean - -78.62982 | Std - 22.87884 | Min - -122.2956 | Max - -56.45991\n",
      "CV Score : Mean - 0.5173398 | Std - 0.06249914 | Min - 0.4006431 | Max - 0.5721799\n"
     ]
    }
   ],
   "source": [
    "# Now time to fit the first model called Model_Lasso_0\n",
    "# This is the model with no regularisation at all.\n",
    "# So the loss function is just the entire RSS\n",
    "Model_Lasso_0 = Lasso(0)\n",
    "# Now fit it on the training data set with default settings and a CV of 5\n",
    "modelfit(Model_Lasso_0,Targets, Predictors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So for alpha set at 0, these are our results. \n",
    "# So we should try and improve on this or at least do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([0, 1])}, pre_dispatch='2*n_jobs',\n",
      "       refit=True, scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:619: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  best_estimator.fit(X, y, **self.fit_params)\n"
     ]
    }
   ],
   "source": [
    "# One of the major parameters to tune is the number of trees that are used\n",
    "# There is no default optimum trees, so we have to tune the number of trees using the parameter n_estimators\n",
    "\n",
    "# Lets test the number of trees from a range of 20 to 80 in steps of 10\n",
    "alphas = np.array([0,1])\n",
    "model = Lasso()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(Predictors,Target)\n",
    "print(grid)\n",
    "\n",
    "# Lets set some parameters\n",
    "# We choose a learning rate of 0.1\n",
    "#gsearch1 = GridSearchCV(estimator = Lasso(),param_grid = param_test1, scoring='r2',n_jobs=4,iid=False, cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.49904, std: 0.03013, params: {'alpha': 0},\n",
       "  mean: 0.37803, std: 0.02256, params: {'alpha': 1}],\n",
       " {'alpha': 0},\n",
       " 0.4990369254318026)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_, grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([ 0.1 ,  0.01,  0.  ])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Stay away from alpha level of 1 basically. \n",
    "\n",
    "# So lets test out a value of 0.1, 0.01 and 0. \n",
    "alphas = np.array([0.1,0.01,0])\n",
    "model = Lasso()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(Predictors,Target)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.54110, std: 0.03828, params: {'alpha': 0.10000000000000001},\n",
       "  mean: 0.55112, std: 0.03804, params: {'alpha': 0.01},\n",
       "  mean: 0.49904, std: 0.03013, params: {'alpha': 0.0}],\n",
       " {'alpha': 0.01},\n",
       " 0.5511156569644466)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_, grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([ 0.01,  0.05,  0.1 ])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# At alpha level of 0.01, the R2 went up but then dropped at 0.1\n",
    "# So our range is 0.01 and .1\n",
    "# Stay away from alpha level of 1 basically. \n",
    "\n",
    "# So lets test out a value between 0.01 and .1\n",
    "alphas = np.array([0.01,0.05,0.1])\n",
    "model = Lasso()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(Predictors,Target)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.55112, std: 0.03804, params: {'alpha': 0.01},\n",
       "  mean: 0.55416, std: 0.03788, params: {'alpha': 0.050000000000000003},\n",
       "  mean: 0.54110, std: 0.03828, params: {'alpha': 0.10000000000000001}],\n",
       " {'alpha': 0.050000000000000003},\n",
       " 0.5541584010459257)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_, grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([ 0.01 ,  0.05 ,  0.025])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# So lets test out a value in-between 0.025\n",
    "alphas = np.array([0.01,0.05,0.025])\n",
    "model = Lasso()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(Predictors,Target)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.55112, std: 0.03804, params: {'alpha': 0.01},\n",
       "  mean: 0.55416, std: 0.03788, params: {'alpha': 0.050000000000000003},\n",
       "  mean: 0.55682, std: 0.03771, params: {'alpha': 0.025000000000000001}],\n",
       " {'alpha': 0.025000000000000001},\n",
       " 0.5568184564200847)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_, grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The optimum range seems to be between alpha levels 0.05 and 0.025. The increase is not that much\n",
    "# So lets pick alpha level 0.025 for our lasso regularisation\n",
    "\n",
    "# Now lets run our lasso program again, this time with alpha at 0.025 and return the coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now lets create the list of alphas\n",
    "Alpha = [0.025]\n",
    "FeatureSelectionWithLasso = lasso(Alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Alpha = 0.025000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X185</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X186</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature Name  Alpha = 0.025000\n",
       "0         X189                 0\n",
       "1         X185                -0\n",
       "2         X184                 0\n",
       "3         X187                 0\n",
       "4         X186                -0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatureSelectionWithLasso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all the features that have a negative non-zero coefficient\n",
    "Model_selection_negative = FeatureSelectionWithLasso[FeatureSelectionWithLasso['Alpha = 0.025000'] < 0]\n",
    "\n",
    "# Get all the features that have a positive non-zero coefficient\n",
    "Model_selection_positive = FeatureSelectionWithLasso[FeatureSelectionWithLasso['Alpha = 0.025000'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see the number of the features that are positively correlated with target y\n",
    "Model_selection_positive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x125a71790>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEACAYAAAB4ayemAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRGSQ/w8+TFh1KIGS7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1259a1a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "Model_selection_positive.plot(style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see the number of the features that are positively correlated with target y\n",
    "Model_selection_negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x125a9f410>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEACAYAAAB8nvebAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwrsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125ab66d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Model_selection_negative.plot(style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So the features that we are going to keep in our model will be 95 features\n",
    "\n",
    "# Lets get those\n",
    "\n",
    "# Lets concatenate both positive and negative \n",
    "Features_95 = pd.concat([Model_selection_positive,Model_selection_negative])\n",
    "\n",
    "# Get the predictor names as a list\n",
    "Features_95_Names = list(Features_95['Feature Name'])\n",
    "\n",
    "# Use those predictors to describe the training data set\n",
    "Training_95_Features = Training[Features_95_Names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X181</th>\n",
       "      <th>X119</th>\n",
       "      <th>X47</th>\n",
       "      <th>X156</th>\n",
       "      <th>X151</th>\n",
       "      <th>X324</th>\n",
       "      <th>X321</th>\n",
       "      <th>X12</th>\n",
       "      <th>X84</th>\n",
       "      <th>X218</th>\n",
       "      <th>...</th>\n",
       "      <th>X5_w</th>\n",
       "      <th>X5_r</th>\n",
       "      <th>X5_s</th>\n",
       "      <th>X5_l</th>\n",
       "      <th>X0_aj</th>\n",
       "      <th>X0_d</th>\n",
       "      <th>X0_h</th>\n",
       "      <th>X0_o</th>\n",
       "      <th>X0_t</th>\n",
       "      <th>X8_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X181  X119  X47  X156  X151  X324  X321  X12  X84  X218  ...   X5_w  X5_r  \\\n",
       "0     0     1    0     1     0     1     0    0    0     0  ...      0     0   \n",
       "1     0     1    0     1     0     0     0    0    0     0  ...      0     0   \n",
       "2     0     0    0     0     0     1     0    0    1     1  ...      0     0   \n",
       "3     0     0    0     0     0     0     0    0    1     1  ...      0     0   \n",
       "4     0     0    0     0     0     0     0    0    0     1  ...      0     0   \n",
       "\n",
       "   X5_s  X5_l  X0_aj  X0_d  X0_h  X0_o  X0_t  X8_x  \n",
       "0     0     0      0     0     0     0     0     0  \n",
       "1     0     0      0     0     0     0     0     0  \n",
       "2     0     0      0     0     0     0     0     1  \n",
       "3     0     0      0     0     0     0     0     0  \n",
       "4     0     0      0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_95_Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now use these 95 features to also describe the test data set\n",
    "# Load test data\n",
    "Test = pd.read_csv('TestDataSet_common_features.csv')\n",
    "# Use the predcitors identifed by lasso regression to describe the test data set\n",
    "Test_95_Features = Test[Features_95_Names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X181</th>\n",
       "      <th>X119</th>\n",
       "      <th>X47</th>\n",
       "      <th>X156</th>\n",
       "      <th>X151</th>\n",
       "      <th>X324</th>\n",
       "      <th>X321</th>\n",
       "      <th>X12</th>\n",
       "      <th>X84</th>\n",
       "      <th>X218</th>\n",
       "      <th>...</th>\n",
       "      <th>X5_w</th>\n",
       "      <th>X5_r</th>\n",
       "      <th>X5_s</th>\n",
       "      <th>X5_l</th>\n",
       "      <th>X0_aj</th>\n",
       "      <th>X0_d</th>\n",
       "      <th>X0_h</th>\n",
       "      <th>X0_o</th>\n",
       "      <th>X0_t</th>\n",
       "      <th>X8_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X181  X119  X47  X156  X151  X324  X321  X12  X84  X218  ...   X5_w  X5_r  \\\n",
       "0     0     0    0     0     0     0     0    0    0     1  ...      0     0   \n",
       "1     0     1    0     1     0     1     0    0    0     1  ...      0     0   \n",
       "2     0     0    0     0     0     1     0    0    0     1  ...      0     0   \n",
       "3     0     0    0     0     0     0     0    0    0     1  ...      0     0   \n",
       "4     0     1    0     1     1     1     0    0    0     0  ...      0     0   \n",
       "\n",
       "   X5_s  X5_l  X0_aj  X0_d  X0_h  X0_o  X0_t  X8_x  \n",
       "0     0     0      0     0     0     0     0     0  \n",
       "1     0     0      0     0     0     0     1     0  \n",
       "2     0     0      0     0     0     0     0     0  \n",
       "3     0     0      0     0     0     0     0     0  \n",
       "4     0     0      0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_95_Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Both train and test seem to be described by the same set of features. So now we can use the train\n",
    "# data set to come up with a model that we can use to make predictions on the test data set.\n",
    "\n",
    "# First save both data sets.\n",
    "Training_95_Features.to_csv('Training_95_Features.csv', sep=',')\n",
    "\n",
    "Test_95_Features.to_csv('Test_95_Features.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The algorithm I want to use is the gradient boosting regression algorithm\n",
    "\n",
    "# Start a new notebook called ModelBuilding_95Features_GBregression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
